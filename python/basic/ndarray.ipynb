{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDArray Tutorial\n",
    "\n",
    "\n",
    "One of the main object in MXNet is the multidimensional array provided by the package `mxnet.ndarray`, or `mxnet.nd` for short. If you familiar with the scientific computing python package [NumPy](http://www.numpy.org/), `mxnet.ndarray` is similar to `numpy.ndarray` in many aspects. \n",
    "\n",
    "## The basic\n",
    "\n",
    "A multidimensional array is a table of numbers with the same type. For example, the coordinates of a point in 3D space `[1, 2, 3]` is a 1-dimensional array with that dimension has a length of 3. The following picture shows a 2-dimensional array. The length of the first dimension is 2, and the second dimension has a length of 3\n",
    "```\n",
    "[[0, 1, 2]\n",
    " [3, 4, 5]]\n",
    "```\n",
    "The array class is called `NDArray`. Some important attributes of a `NDArray` object are:\n",
    "\n",
    "- **ndarray.shape** the dimensions of the array. It is a tuple of integers indicating the length of the array in each dimension. For a matrix with `n` rows and `m` columns, the `shape` will be `(n, m)`.  \n",
    "- **ndarray.dtype** an `numpy` object describing the type of the elements.\n",
    "- **ndarray.size** the total number(总的数量) of numbers in the array, which equals to the product of the elements of `shape`\n",
    "- **ndarray.context** the device this array is stored. A device can be the CPU or the i-th GPU.\n",
    "- **ndarray.handle** the pointer to the according C++ object. Normally we won't need to use this attribute. \n",
    "\n",
    "### An example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': cpu(0),\n",
       " 'data type': numpy.float32,\n",
       " 'shape': (1L, 2L),\n",
       " 'size': 2,\n",
       " 'type': mxnet.ndarray.NDArray}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "a = mx.nd.array([[2,3]])\n",
    "{'shape': a.shape, 'size':a.size, 'data type':a.dtype, 'context':a.context, 'type':type(a)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Creation \n",
    "An array can be created in multiple ways. For example, we can create an array from a regular Python list or tuple by using the `array` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = mx.nd.array([1,2,3])  # create a 1-dimensional array with a python list\n",
    "b = mx.nd.array([[1,2,3], [2,3,4]])  # create a 2-dimensional array with a nested（嵌套） python list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or even from an `numpy.ndarray` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "c = np.arange(15).reshape(3,5)\n",
    "a = mx.nd.array(c)  # create a 2-dimensional array from a numpy.ndarray object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the element type with the option `dtype`, which accepts a numpy type. In default, `float32` is used. \n",
    "#我们能够指定元素的类型和精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.float32, numpy.int32, numpy.float16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = mx.nd.array([1,2,3])  # float32 is used in deafult\n",
    "b = mx.nd.array([1,2,3], dtype=np.int32)  # create an int32 array\n",
    "c = mx.nd.array([1.2, 2.3], dtype=np.float16)  # create a 16-bit float array\n",
    "(a.dtype, b.dtype, c.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we only know the size but not the element values, there are several functions to create arrays with initial placeholder content. \n",
    "当我们只知道size而不知道元素值时，我们可以利用下面的方法初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = mx.nd.zeros((2,3))    # create a 2-dimensional array full of zeros with shape (2,3)  \n",
    "b = mx.nd.ones((2,3))     # create a same shape array full of ones\n",
    "c = mx.nd.full((2,3), 7)  # create a same shape array with all elements set to 7\n",
    "d = mx.nd.empty((2,3))    # create a same shape whose initial content is random and depends on the state of the memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing Arrays\n",
    "###NDArray是无法直接打印的，我们必须利用函数asnumpy，将NDArray转换成numpy.ndarray,才能打印。\n",
    "We often first convert `NDArray` to `numpy.ndarray` by the function `asnumpy` for printing. Numpy uses the following layout:\n",
    "- the last axis is printed from left to right,\n",
    "- the second-to-last is printed from top to bottom,\n",
    "- the rest are also printed from top to bottom, with each slice separated from the next by an empty line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "b = mx.nd.ones((2,3))\n",
    "print(b.asnumpy())\n",
    "c = mx.nd.zeros((1000,1000))\n",
    "print(c.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copies\n",
    "### 复制操作，在python里不能用“=”去复制，在python“=”是引用操作，要想复制，必须使用函数完成\n",
    "Data is *NOT* copied in normal assignment and function arguments passing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "140484456318800\n",
      "140484456318800\n"
     ]
    }
   ],
   "source": [
    "a = mx.nd.ones((2,2))\n",
    "b = a  # copy by reference \n",
    "print(b is a)\n",
    "def f(x):  # also copy by reference\n",
    "    print(id(x))\n",
    "f(a)\n",
    "print(id(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####The `copy` method makes a deep copy of the array and its data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "b = a.copy()\n",
    "print (b is a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####We can also use the `copyto` method or the slice operator `[]` to avoid additional memory allocation \n",
    "####可以避免额外的内存开销"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140484456317456\n",
      "140484456317456\n",
      "140484456317456\n"
     ]
    }
   ],
   "source": [
    "b = mx.nd.ones(a.shape)\n",
    "print(id(b))\n",
    "b[:] = a\n",
    "print(id(b))\n",
    "a.copyto(b)\n",
    "print(id(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Operations\n",
    "### 基本操作\n",
    "Arithmetic operators on arrays apply *elementwise*. A new array is created and filled with the result.\n",
    "##元素级别元素\n",
    "算上运算是`元素级别`的，一个新的数组被创建并且用结果填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2. -2. -2.]\n",
      " [-2. -2. -2.]]\n",
      "[[-0.7568025 -0.7568025]\n",
      " [-0.7568025 -0.7568025]\n",
      " [-0.7568025 -0.7568025]]\n",
      "[[ 2.  2.  2.]\n",
      " [ 2.  2.  2.]]\n"
     ]
    }
   ],
   "source": [
    "a = mx.nd.ones((2,3))\n",
    "b = mx.nd.ones((2,3))\n",
    "c = a + b  # elementwise plus\n",
    "d = - c    # elementwise minus\n",
    "print(d.asnumpy())\n",
    "e = mx.nd.sin(c**2).T  # elementwise pow and sin, and then transpose\n",
    "print(e.asnumpy())\n",
    "f = mx.nd.maximum(a, c)  # elementwise max\n",
    "print(f.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Simiar to `NumPy`, `*` is used for elementwise multiply, while matrix-matrix multiplication is left for `dot`\n",
    "####`*`对应元素相乘，`dot`矩阵相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.]\n",
      " [ 1.  1.]]\n",
      "[[ 2.  2.]\n",
      " [ 2.  2.]]\n"
     ]
    }
   ],
   "source": [
    "a = mx.nd.ones((2,2))\n",
    "b = a * a\n",
    "c = mx.nd.dot(a,a)\n",
    "print(b.asnumpy())\n",
    "print(c.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assignment operators（复制运算符） such as `+=` and `*=` act in place（内部运算） to modify an existing array rather than create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140484456318736\n",
      "140484456318736\n",
      "[[ 2.  2.]\n",
      " [ 2.  2.]]\n"
     ]
    }
   ],
   "source": [
    "a = mx.nd.ones((2,2))\n",
    "b = mx.nd.ones(a.shape)\n",
    "print(id(b))\n",
    "b += a\n",
    "print(id(b))\n",
    "print(b.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and Slicing\n",
    "The slice operator `[]` applies on axis 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.]\n",
      " [ 2.  3.]\n",
      " [ 4.  5.]]\n",
      "[[ 0.  1.]\n",
      " [ 1.  1.]\n",
      " [ 4.  5.]]\n"
     ]
    }
   ],
   "source": [
    "a = mx.nd.array(np.arange(6).reshape(3,2))\n",
    "print(a[:].asnumpy())\n",
    "a[1:2] = 1\n",
    "print(a.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also slice a particular（详细的） axis with the method `slice_axis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 5.]]\n"
     ]
    }
   ],
   "source": [
    "d = mx.nd.slice_axis(a, axis=1, begin=1, end=2)\n",
    "print d.asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape Manipulation \n",
    "### Shape 操作\n",
    "The shape of the array can be changed as long as（只要） the size remaining the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   1.   2.   3.   4.   5.]\n",
      " [  6.   7.   8.   9.  10.  11.]\n",
      " [ 12.  13.  14.  15.  16.  17.]\n",
      " [ 18.  19.  20.  21.  22.  23.]]\n",
      "[[[  0.   1.   2.   3.]\n",
      "  [  4.   5.   6.   7.]\n",
      "  [  8.   9.  10.  11.]]\n",
      "\n",
      " [[ 12.  13.  14.  15.]\n",
      "  [ 16.  17.  18.  19.]\n",
      "  [ 20.  21.  22.  23.]]]\n"
     ]
    }
   ],
   "source": [
    "a = mx.nd.array(np.arange(24).reshape(4,6))\n",
    "print(a.asnumpy())\n",
    "b = a.reshape((2,3,4))#维度的数目也能改变\n",
    "print(b.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Method `concatenate` stacks multiple arrays along the first dimension. (Their shapes must be the same).\n",
    "####`concatenate`方法将多个数组沿着第一个维度连接起来，这些数组的shape必须相同，否则就无法连接起来了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 2.  2.  2.]\n",
      " [ 2.  2.  2.]]\n"
     ]
    }
   ],
   "source": [
    "a = mx.nd.ones((2,3))\n",
    "b = mx.nd.ones((2,3))*2\n",
    "c = mx.nd.concatenate([a,b])\n",
    "print(c.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce\n",
    "### 求和，降低\n",
    "\n",
    "We can reduce the array to a scalar, or along a particular axis.\n",
    "我们能降低数组到一个`标量`，或者沿着一个特定的轴，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.]\n",
      "[ 3.  3.]\n"
     ]
    }
   ],
   "source": [
    "a = mx.nd.ones((2,3))\n",
    "b = mx.nd.sum(a)  # sum over all elements\n",
    "print(b.asnumpy())\n",
    "c = mx.nd.sum_axis(a, axis=1)  # sum over axis 1\n",
    "print(c.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcast\n",
    "# 广播操作\n",
    "We can also broadcast an array by duplicating（复制）."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.]\n",
      " [ 1.  1.]\n",
      " [ 2.  2.]\n",
      " [ 3.  3.]\n",
      " [ 4.  4.]\n",
      " [ 5.  5.]]\n",
      "[[[[ 0.  1.  2.]\n",
      "   [ 0.  1.  2.]]\n",
      "\n",
      "  [[ 0.  1.  2.]\n",
      "   [ 0.  1.  2.]]]\n",
      "\n",
      "\n",
      " [[[ 3.  4.  5.]\n",
      "   [ 3.  4.  5.]]\n",
      "\n",
      "  [[ 3.  4.  5.]\n",
      "   [ 3.  4.  5.]]]]\n"
     ]
    }
   ],
   "source": [
    "a = mx.nd.array(np.arange(6).reshape(6,1))\n",
    "b = a.broadcast_to((6,2))  # broadcast along axis 1\n",
    "print(b.asnumpy())\n",
    "c = a.reshape((2,1,1,3))\n",
    "d = c.broadcast_to((2,2,2,3))  # broadcast along axes 1 and 2.\n",
    "print(d.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcast can be applied to operations such as `*` and `+`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  2.]\n",
      " [ 2.  2.]\n",
      " [ 2.  2.]]\n"
     ]
    }
   ],
   "source": [
    "a = mx.nd.ones((3,1))\n",
    "b = mx.nd.ones((1,2))\n",
    "c = a + b #当维度不一样时，将会自动调整维度\n",
    "print(c.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Advanced \n",
    "There are some advanced features in `mxnet.ndarray` which make mxnet different from other libraries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Support\n",
    "\n",
    "In default operators are executed on CPU. It is easy to switch to another computation resource, such as GPU, if available. The device information is stored in `ndarray.context`. When MXNet is compiled with flag `USE_CUDA=1` and there is at least one Nvidia GPU card, we can make all computations run on GPU 0 by using context `mx.gpu(0)`, or simply `mx.gpu()`. If there are more than two GPUs, the 2nd GPU is represented by `mx.gpu(1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('running on ', cpu(0))\n",
      "[[ 2.  2.  2. ...,  2.  2.  2.]\n",
      " [ 2.  2.  2. ...,  2.  2.  2.]\n",
      " [ 2.  2.  2. ...,  2.  2.  2.]\n",
      " ..., \n",
      " [ 2.  2.  2. ...,  2.  2.  2.]\n",
      " [ 2.  2.  2. ...,  2.  2.  2.]\n",
      " [ 2.  2.  2. ...,  2.  2.  2.]]\n",
      "('running on ', gpu(0))\n",
      "[[ 2.  2.  2. ...,  2.  2.  2.]\n",
      " [ 2.  2.  2. ...,  2.  2.  2.]\n",
      " [ 2.  2.  2. ...,  2.  2.  2.]\n",
      " ..., \n",
      " [ 2.  2.  2. ...,  2.  2.  2.]\n",
      " [ 2.  2.  2. ...,  2.  2.  2.]\n",
      " [ 2.  2.  2. ...,  2.  2.  2.]]\n"
     ]
    }
   ],
   "source": [
    "def f():\n",
    "    a = mx.nd.ones((100,100))\n",
    "    b = mx.nd.ones((100,100))\n",
    "    c = a + b\n",
    "    print('running on ', c.context)\n",
    "    print(c.asnumpy())\n",
    "f()  # in default mx.cpu() is used\n",
    "with mx.Context(mx.gpu()):  # change the default context to the first GPU 统一指明\n",
    "    f()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also explicitly specify the context when creating an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu(0)\n"
     ]
    }
   ],
   "source": [
    "a = mx.nd.ones((100, 100), mx.gpu(0))#分别精确指明\n",
    "b = mx.nd.ones((100, 100), mx.gpu(0))\n",
    "c = a + b\n",
    "print(c.context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Currently MXNet requires two arrays to `sit on the same device for computation`. There are several methods for copying data between devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu(0)\n",
      "gpu(0)\n"
     ]
    }
   ],
   "source": [
    "a = mx.nd.ones((100,100), mx.cpu())\n",
    "b = mx.nd.ones((100,100), mx.gpu())\n",
    "c = mx.nd.ones((100,100), mx.gpu())\n",
    "a.copyto(c)  # copy from CPU to GPU\n",
    "d = b + c\n",
    "print(d.context)\n",
    "e = b.as_in_context(c.context) + c  # same to above\n",
    "print(e.context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize(序列化) From/To (Distributed) Filesystems  \n",
    "###保存和加载\n",
    "There are two ways to save data to (load from) disks easily. The first way uses `pickle`. `NDArray` is pickle compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.]\n",
      " [ 1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "a = mx.nd.ones((2, 3))\n",
    "# pack and then dump（倾倒） into disk\n",
    "data = pkl.dumps(a)\n",
    "pkl.dump(data, open('tmp.pickle', 'wb'))\n",
    "# load from disk and then unpack \n",
    "data = pkl.load(open('tmp.pickle', 'rb'))\n",
    "b = pkl.loads(data)\n",
    "print(b.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second way is to directly dump into disk in binary format by method `save` and `load`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "[[ 2.  2.  2.]\n",
      " [ 2.  2.  2.]]\n"
     ]
    }
   ],
   "source": [
    "# load and save a list\n",
    "a = mx.nd.ones((2,3))\n",
    "b = mx.nd.ones((2,3))*2               \n",
    "mx.nd.save(\"temp.ndarray\", [a,b])\n",
    "c = mx.nd.load(\"temp.ndarray\")\n",
    "print(c[0].asnumpy())\n",
    "print(c[1].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "[[ 2.  2.  2.]\n",
      " [ 2.  2.  2.]]\n"
     ]
    }
   ],
   "source": [
    "# load and save a dict\n",
    "mx.nd.save(\"temp.ndarray\", {'a':a, 'b':b})#保存成字典的形式\n",
    "c = mx.nd.load(\"temp.ndarray\")\n",
    "print(c['a'].asnumpy())\n",
    "print(c['b'].asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The load/save is better than pickle in two aspects\n",
    "1. The data saved with the Python interface can be used by another lanuage binding. For example, if we save the data in python:\n",
    "```python\n",
    "a = mx.nd.ones((2, 3))\n",
    "mx.save(\"temp.ndarray\", [a,])\n",
    "```\n",
    "then we can load it into R:\n",
    "```R\n",
    "a <- mx.nd.load(\"temp.ndarray\")\n",
    "as.array(a[[1]])\n",
    "##      [,1] [,2] [,3]\n",
    "## [1,]    1    1    1\n",
    "## [2,]    1    1    1\n",
    "```\n",
    "2. If a distributed filesystem such as Amazon S3 or Hadoop HDFS is set up, we can directly save to and load from it. \n",
    "```python\n",
    "mx.nd.save('s3://mybucket/mydata.ndarray', [a,])  # if compiled with USE_S3=1\n",
    "mx.nd.save('hdfs///users/myname/mydata.bin', [a,])  # if compiled with USE_HDFS=1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lazy Evaluation（惰性计算） and Auto Parallelization *\n",
    "\n",
    "MXNet uses lazy evaluation for better performance. When we run `a=b+1` in python, the python thread just pushs the operation into the backend engine and then returns. There are two benefits for such optimization:\n",
    "1. The main python thread can continue to execute（执行） other computations once the previous one is pushed. It is useful for frontend languages with heavy overheads. \n",
    "2. It is easier for the backend engine to explore further optimization, such as auto parallelization that will be discussed shortly. \n",
    "\n",
    "The backend engine is able to resolve（决定） the data dependencies（依赖性） and schedule（安排） the computations correctly. It is transparent to frontend users. We can explicitly call the method `wait_to_read` on the result array to wait the computation finished. Operations that copy data from an array to other packages, such as `asnumpy`, will implicitly（含蓄） call `wait_to_read`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for all computations are pushed into the backend engine: 0.002128 sec\n",
      "time for all computations are finished: 0.820602 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def do(x, n):\n",
    "    \"\"\"push computation into the backend engine\"\"\"\n",
    "    return [mx.nd.dot(x,x) for i in range(n)]\n",
    "def wait(x):\n",
    "    \"\"\"wait until all results are available\"\"\"\n",
    "    for y in x:\n",
    "        y.wait_to_read()\n",
    "        \n",
    "tic = time.time()\n",
    "a = mx.nd.ones((1000,1000))\n",
    "b = do(a, 50)\n",
    "toc = time.time() - tic\n",
    "print('time for all computations are pushed into the backend engine: %f sec' % (time.time() - tic))\n",
    "wait(b)\n",
    "print('time for all computations are finished: %f sec' % (time.time() - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides analyzing data read and write dependencies, the backend engine is able to schedule computations with no dependency in parallel. For example, in the following codes\n",
    "```python\n",
    "a = mx.nd.ones((2,3))\n",
    "b = a + 1\n",
    "c = a + 2\n",
    "d = b * c\n",
    "```\n",
    "the second and third sentences can be executed in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for all computations are finished: 1.437338 sec\n"
     ]
    }
   ],
   "source": [
    "# run computation on CPU first, and then on GPU\n",
    "n = 50\n",
    "a = mx.nd.ones((1000,1000))\n",
    "b = mx.nd.ones((2000,2000), mx.gpu())\n",
    "tic = time.time()\n",
    "c = do(a, n)\n",
    "wait(c)\n",
    "d = do(b, n)\n",
    "wait(d)\n",
    "print('time for all computations are finished: %f sec' % (time.time() - tic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "improved parallelization: 1.104402 sec\n"
     ]
    }
   ],
   "source": [
    "# the backend engine will try to parallel the CPU and GPU computation.\n",
    "tic = time.time()\n",
    "c = do(a, n)\n",
    "d = do(b, n)\n",
    "wait(c)\n",
    "wait(d)\n",
    "print('improved parallelization: %f sec' % (time.time() - tic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Status\n",
    "\n",
    "We try our best to keep the NDArray API as the same numpy's. But it is not fully numpy compatible yet. Here we summary some major difference, which we hope to be fixed in a short time. We are also welcome to any contribution.\n",
    "\n",
    "- Slice and Index. \n",
    "    - NDArray can only slice one dimension at each time, namely we cannot use `x[:, 1]` to slice both dimensions.\n",
    "    - Only continues indexes are supported, we cannot do `x[1:2:3]`\n",
    "    - boolean indices are not supported, such as `x[y==1]`.\n",
    "- Lack of reduce functions such as `max`, `min`...\n",
    "\n",
    "## Futher Readings\n",
    "- [NDArray API](http://mxnet.dmlc.ml/en/latest/packages/python/ndarray.html) Documents for all NDArray methods.\n",
    "- [MinPy](https://github.com/dmlc/minpy) on-going project, fully numpy compatible with GPU and auto differentiation supports "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
